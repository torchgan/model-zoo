{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary `modules` from `torch` and `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now import the necessary things from `torchgan`. For a detailed list of `losses`, `models` and `trainers` checkout the `torchgan documentation`.\n",
    "\n",
    "We are loading the `SmallDCGAN` model instead of `DCGAN` this is because we will be using $32 \\times 32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgan import *\n",
    "from torchgan.models import SmallDCGANGenerator, SmallDCGANDiscriminator\n",
    "from torchgan.losses import MinimaxGeneratorLoss, MinimaxDiscriminatorLoss,\\\n",
    "                            LeastSquaresDiscriminatorLoss, LeastSquaresGeneratorLoss\n",
    "from torchgan.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the required `functions` and `classes`, we need to write the `data loader`. In a future version of torchgan we will provide data loaders for some common datasets, but lets write that manually for now.\n",
    "\n",
    "We use the `torchvision.datasets` to fetch `MNIST` for us. But MNIST has $28 \\times 28$ dimensions, but our smallest models support $32 \\times 32$. So we shall just pad the images before loading. Note that the trainer needs the `DataLoader` to work as it is supposed to.\n",
    "\n",
    "Also donot forget to change the `root` as per your requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_dataloader():\n",
    "    train_dataset = dsets.MNIST(root='/path/to/data', train=True,\n",
    "                                transform=transforms.Compose([transforms.Pad((2, 2)),\n",
    "                                                              transforms.ToTensor(),\n",
    "                                                              transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))]),\n",
    "                                download=True)\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `MNIST` is `Grayscale`, we set the `channels` to `1`. You can experiment with the parameters like `step_channels` and `optimizer` but we found these to be good enough. Change the `device`, `checkpoints` and `recon` parameters if needed. Feed in a `dict` with all the optimizer options that can be applicable for the optimizer you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(SmallDCGANGenerator(out_channels=1, step_channels=16),\n",
    "                  SmallDCGANDiscriminator(in_channels=1, step_channels=16),\n",
    "                  Adam, Adam, LeastSquaresGeneratorLoss, LeastSquaresDiscriminatorLoss,\n",
    "                  sample_size=64, epochs=20, verbose=5, device=torch.device(\"cuda:1\"),\n",
    "                  checkpoints=\"./model/gan\", recon=\"./images\",\n",
    "                  optimizer_generator_options={\"lr\": 0.0002, \"betas\": (0.5, 0.999)},\n",
    "                  optimizer_discriminator_options={\"lr\": 0.0002, \"betas\": (0.5, 0.999)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now send the MNIST DataLoader and watch the training either here or use `tensorboard`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(mnist_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block we use the `Minimax Loss`. This essentially demonstrates how you can seamlessly change loss function and run experiments fast with minimal code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(SmallDCGANGenerator(out_channels=1, step_channels=16),\n",
    "                  SmallDCGANDiscriminator(in_channels=1, step_channels=16),\n",
    "                  Adam, Adam, MinimaxGeneratorLoss, MinimaxDiscriminatorLoss,\n",
    "                  sample_size=64, epochs=20, verbose=5, device=torch.device(\"cuda:1\"),\n",
    "                  checkpoints=\"./model/gan\", recon=\"./images\",\n",
    "                  optimizer_generator_options={\"lr\": 0.0002, \"betas\": (0.5, 0.999)},\n",
    "                  optimizer_discriminator_options={\"lr\": 0.0002, \"betas\": (0.5, 0.999)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer(mnist_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
